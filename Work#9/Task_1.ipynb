{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотеки Python для DS (семинары)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Урок 9. Использование на практике методов снижения размерности\n",
    "\n",
    "Использование алгоритмов понижения размерности для улучшения классификации новостей (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html)\n",
    "\n",
    "Цель задания: Исследовать влияние различных методов понижения размерности на качество классификации текстовых данных.\n",
    "\n",
    "Датасет: Набор данных новостных статей\n",
    "(датасет '20 Newsgroups' доступный в sklearn.datasets).\n",
    "\n",
    "Задачи:\n",
    "\n",
    "1. Загрузите датасет '20 Newsgroups' из sklearn.\n",
    "\n",
    "2. Проведите предобработку данных (очистка текста, удаление стоп-слов, векторизация с использованием TF-IDF).\n",
    "\n",
    "3. Примените к полученным векторам TF-IDF следующие методы понижения размерности:\n",
    "— PCA (Principal Component Analysis)\n",
    "— t-SNE (t-distributed Stochastic Neighbor Embedding)\n",
    "— UMAP (Uniform Manifold Approximation and Projection).\n",
    "\n",
    "4. После понижения размерности данных используйте любой метод машинного обучения для классификации новостей по темам.\n",
    "\n",
    "5. Сравните качество классификации для каждого метода понижения размерности. Используйте метрики точности и F1-меру.\n",
    "\n",
    "6. Визуализируйте двумерное представление данных для каждого метода понижения размерности, чтобы оценить, как алгоритмы справляются с сепарацией классов.\n",
    "\n",
    "7. Напишите отчёт, в котором обсудите, какой метод понижения размерности оказал наиболее значительное влияние на качество классификации и почему.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выполнение домашней работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Используем предоставленый к заданию файл fetch_california_housing.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека для загрузки датасета\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import joblib\n",
    "# Библиотеки для работы с датасетом и графиками\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Загрузите датасет '20 Newsgroups' из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество документов: 18846\n",
      "Количество классов: 20\n"
     ]
    }
   ],
   "source": [
    "# Загрузка датасета\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Просмотр информации о датасете\n",
    "print(f\"Количество документов: {len(newsgroups.data)}\")\n",
    "print(f\"Количество классов: {len(newsgroups.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет сохранен в папке: 20_newsgroups_data\n"
     ]
    }
   ],
   "source": [
    "# Указываем путь к папке\n",
    "output_dir = '20_newsgroups_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Сохраняем документы в текстовые файлы\n",
    "for i, (doc, label) in enumerate(zip(newsgroups.data, newsgroups.target)):\n",
    "    # Создаем имя файла на основе индекса документа\n",
    "    file_name = os.path.join(output_dir, f'document_{i}.txt')\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        f.write(doc)\n",
    "\n",
    "# Сохраняем метки классов в отдельный файл\n",
    "labels_file_path = os.path.join(output_dir, 'labels.txt')\n",
    "with open(labels_file_path, 'w', encoding='utf-8') as f:\n",
    "    for label in newsgroups.target:\n",
    "        f.write(f\"{label}\\n\")\n",
    "\n",
    "print(f\"Датасет сохранен в папке: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20_newsgroups_data.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка датасета\n",
    "newsgroups_data = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Сохранение данных в файл\n",
    "joblib.dump(newsgroups_data, '20_newsgroups_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: Mamatha Devineni Ratnam &lt;mr47+@andrew.cm...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: mblawson@midway.ecn.uoknor.edu (Matthew ...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: Alexander Samuel McDiarmid &lt;am2o+@andrew...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>From: rdell@cbnewsf.cb.att.com (richard.b.dell...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>From: chriss@netcom.com (Chris Silvester)\\nSub...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "0      From: Mamatha Devineni Ratnam <mr47+@andrew.cm...      10   \n",
       "1      From: mblawson@midway.ecn.uoknor.edu (Matthew ...       3   \n",
       "2      From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...      17   \n",
       "3      From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...       3   \n",
       "4      From: Alexander Samuel McDiarmid <am2o+@andrew...       4   \n",
       "...                                                  ...     ...   \n",
       "18841  From: jim.zisfein@factory.com (Jim Zisfein) \\n...      13   \n",
       "18842  From: rdell@cbnewsf.cb.att.com (richard.b.dell...      12   \n",
       "18843  From: westes@netcom.com (Will Estes)\\nSubject:...       3   \n",
       "18844  From: steve@hcrlgw (Steven Collins)\\nSubject: ...       1   \n",
       "18845  From: chriss@netcom.com (Chris Silvester)\\nSub...       7   \n",
       "\n",
       "                       category  \n",
       "0              rec.sport.hockey  \n",
       "1      comp.sys.ibm.pc.hardware  \n",
       "2         talk.politics.mideast  \n",
       "3      comp.sys.ibm.pc.hardware  \n",
       "4         comp.sys.mac.hardware  \n",
       "...                         ...  \n",
       "18841                   sci.med  \n",
       "18842           sci.electronics  \n",
       "18843  comp.sys.ibm.pc.hardware  \n",
       "18844             comp.graphics  \n",
       "18845                 rec.autos  \n",
       "\n",
       "[18846 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных из файла\n",
    "# newsgroups_data = joblib.load('20_newsgroups_data.pkl')\n",
    "newsgroups_data = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Создание DataFrame\n",
    "data = {\n",
    "    'text': newsgroups_data.data,\n",
    "    'target': newsgroups_data.target}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Добавление категорий\n",
    "df['category'] = df['target'].apply(lambda x: newsgroups_data.target_names[x])\n",
    "\n",
    "# Вывод DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Проведите предобработку данных (очистка текста, удаление стоп-слов, векторизация с использованием TF-IDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Примените к полученным векторам TF-IDF следующие методы понижения размерности:\n",
    "\n",
    "— PCA (Principal Component Analysis)\n",
    "\n",
    "— t-SNE (t-distributed Stochastic Neighbor Embedding)\n",
    "\n",
    "— UMAP (Uniform Manifold Approximation and Projection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. После понижения размерности данных используйте любой метод машинного обучения для классификации новостей по темам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Сравните качество классификации для каждого метода понижения размерности. Используйте метрики точности и F1-меру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Визуализируйте двумерное представление данных для каждого метода понижения размерности, чтобы оценить, как алгоритмы справляются с сепарацией классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Напишите отчёт, в котором обсудите, какой метод понижения размерности оказал наиболее значительное влияние на качество классификации и почему."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
